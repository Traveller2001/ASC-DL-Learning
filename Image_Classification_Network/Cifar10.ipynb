{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 在预训练resnet18模型中加入CBAM注意力机制进而到数据增广的cifar10上微调实现精度较高的分类任务"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-04-16T11:25:24.687193Z","iopub.status.busy":"2022-04-16T11:25:24.686806Z","iopub.status.idle":"2022-04-16T11:25:34.382528Z","shell.execute_reply":"2022-04-16T11:25:34.381311Z","shell.execute_reply.started":"2022-04-16T11:25:24.687088Z"},"trusted":true},"outputs":[],"source":["! pip install d2l"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-04-16T11:25:34.386263Z","iopub.status.busy":"2022-04-16T11:25:34.385903Z","iopub.status.idle":"2022-04-16T11:25:35.077995Z","shell.execute_reply":"2022-04-16T11:25:35.077014Z","shell.execute_reply.started":"2022-04-16T11:25:34.386207Z"},"trusted":true},"outputs":[],"source":["%matplotlib inline\n","import os\n","import torch\n","import torchvision\n","from torch import nn\n","from d2l import torch as d2l\n","os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-04-16T11:25:35.079920Z","iopub.status.busy":"2022-04-16T11:25:35.079443Z","iopub.status.idle":"2022-04-16T11:25:35.358131Z","shell.execute_reply":"2022-04-16T11:25:35.357114Z","shell.execute_reply.started":"2022-04-16T11:25:35.079848Z"},"trusted":true},"outputs":[],"source":["finetune_net = torchvision.models.resnet18(pretrained=True)\n","b0 = nn.Linear(1000, 256)\n","b1 = nn.ReLU()\n","b2 = nn.Linear(256,10)\n","finetune_net.add_module(\"fc0\",b0)\n","finetune_net.add_module(\"fc1\",b1)\n","finetune_net.add_module(\"fc2\",b2)\n","nn.init.xavier_uniform_(finetune_net.fc0.weight)\n","nn.init.xavier_uniform_(finetune_net.fc2.weight)\n","print(finetune_net)"]},{"cell_type":"markdown","metadata":{},"source":["- 加入CBAM注意力机制"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-04-16T11:25:35.362695Z","iopub.status.busy":"2022-04-16T11:25:35.360811Z","iopub.status.idle":"2022-04-16T11:25:35.381266Z","shell.execute_reply":"2022-04-16T11:25:35.380101Z","shell.execute_reply.started":"2022-04-16T11:25:35.362645Z"},"trusted":true},"outputs":[],"source":["class CALayer(nn.Module):  # Channel Attention (CA) Layer\n","    def __init__(self, in_channels, reduction=16, pool_types=['avg', 'max']):\n","        super().__init__()\n","        self.pool_list = ['avg', 'max']\n","        self.pool_types = pool_types\n","        self.in_channels = in_channels\n","        self.Pool = [nn.AdaptiveAvgPool2d(\n","            1), nn.AdaptiveMaxPool2d(1, return_indices=False)]\n","        self.conv_ca = nn.Sequential(\n","            nn.Conv2d(in_channels, in_channels //\n","                      reduction, 1, padding=0, bias=True),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels // reduction,\n","                      in_channels, 1, padding=0, bias=True)\n","        )\n","\n","    def forward(self, x):\n","        for (i, pool_type) in enumerate(self.pool_types):\n","            pool = self.Pool[self.pool_list.index(pool_type)](x)\n","            channel_att_raw = self.conv_ca(pool)\n","            if i == 0:\n","                channel_att_sum = channel_att_raw\n","            else:\n","                channel_att_sum += channel_att_raw\n","        scale = F.sigmoid(channel_att_sum)\n","        return x * scale\n","\n","\n","class SALayer(nn.Module):  # Spatial Attention Layer\n","    def __init__(self):\n","        super().__init__()\n","        self.conv_sa = nn.Sequential(\n","            nn.Conv2d(2, 1, 3, 1, 1, bias=False),\n","            nn.BatchNorm2d(1, momentum=0.01),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        x_compress = torch.cat(\n","            (torch.max(x, 1, keepdim=True)[0], torch.mean(x, dim=1, keepdim=True)), dim=1)\n","        scale = self.conv_sa(x_compress)\n","        return x * scale\n","\n","\n","class CBAM(nn.Module):\n","    def __init__(self, in_channels, reduction=2, pool_types=['avg', 'max']):\n","        super().__init__()\n","        self.CALayer = CALayer(\n","            in_channels, reduction, pool_types)\n","        self.SALayer = SALayer()\n","\n","    def forward(self, x):\n","        x_out = self.CALayer(x)\n","        x_out = self.SALayer(x_out)\n","        return x_out"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-04-16T11:25:35.383310Z","iopub.status.busy":"2022-04-16T11:25:35.382815Z","iopub.status.idle":"2022-04-16T11:25:35.399075Z","shell.execute_reply":"2022-04-16T11:25:35.398074Z","shell.execute_reply.started":"2022-04-16T11:25:35.383244Z"},"trusted":true},"outputs":[],"source":["finetune_net.add_module(\"CBAM\",CBAM(10))"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-04-16T11:25:35.401922Z","iopub.status.busy":"2022-04-16T11:25:35.400800Z","iopub.status.idle":"2022-04-16T11:25:35.412583Z","shell.execute_reply":"2022-04-16T11:25:35.411514Z","shell.execute_reply.started":"2022-04-16T11:25:35.401878Z"},"trusted":true},"outputs":[],"source":["# 使用RGB通道的均值和标准差，以标准化每个通道\n","normalize = torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","# Normalize a tensor image with mean and standard deviation. \n","# This transform does not support PIL Image. Given mean: (mean[1],...,mean[n]) and std: (std[1],..,std[n]) for n channels, this transform will normalize each channel of the input torch.*Tensor i.e., output[channel] = (input[channel] - mean[channel]) / std[channel]\n","train_augs = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize(256),\n","    torchvision.transforms.RandomResizedCrop(224),\n","    torchvision.transforms.RandomHorizontalFlip(),\n","    torchvision.transforms.ToTensor(),normalize])\n","\n","test_augs = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize(256),\n","    torchvision.transforms.CenterCrop(224),\n","    torchvision.transforms.ToTensor(),normalize])"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-04-16T11:25:35.415223Z","iopub.status.busy":"2022-04-16T11:25:35.414814Z","iopub.status.idle":"2022-04-16T11:25:35.427384Z","shell.execute_reply":"2022-04-16T11:25:35.426227Z","shell.execute_reply.started":"2022-04-16T11:25:35.415099Z"},"trusted":true},"outputs":[],"source":["def load_cifar10(is_train, augs, batch_size):\n","    dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=is_train,\n","                                           transform=augs, download=True)\n","    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n","                    shuffle=is_train, num_workers=d2l.get_dataloader_workers())\n","    return dataloader"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-04-16T11:25:35.430105Z","iopub.status.busy":"2022-04-16T11:25:35.429658Z","iopub.status.idle":"2022-04-16T11:25:35.450665Z","shell.execute_reply":"2022-04-16T11:25:35.449457Z","shell.execute_reply.started":"2022-04-16T11:25:35.430057Z"},"trusted":true},"outputs":[],"source":["#@save\n","def train_batch_ch13(net, X, y, loss, trainer, devices):\n","    \"\"\"用多GPU进行小批量训练\"\"\"\n","    if isinstance(X, list):\n","        # 微调BERT中所需（稍后讨论）\n","        X = [x.to(devices[0]) for x in X]\n","    else:\n","        X = X.to(devices[0])\n","    y = y.to(devices[0])\n","    net.train()\n","    trainer.zero_grad()\n","    pred = net(X)\n","    l = loss(pred, y)\n","    l.sum().backward()\n","    trainer.step()\n","    train_loss_sum = l.sum()\n","    train_acc_sum = d2l.accuracy(pred, y)\n","    return train_loss_sum, train_acc_sum\n","\n","#@save\n","def train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs,devices=d2l.try_all_gpus()):\n","    \"\"\"用多GPU进行模型训练\"\"\"\n","    timer, num_batches = d2l.Timer(), len(train_iter)\n","    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0, 1],\n","                            legend=['train loss', 'train acc', 'test acc'])\n","    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n","    scheduler = torch.optim.lr_scheduler.StepLR(trainer, 4, 0.9)#加入调学习率的优化器\n","    for epoch in range(num_epochs):\n","        # 4个维度：储存训练损失，训练准确度，实例数，特点数\n","        metric = d2l.Accumulator(4)\n","        for i, (features, labels) in enumerate(train_iter):\n","            timer.start()\n","            l, acc = train_batch_ch13(net, features, labels, loss, trainer, devices)\n","            metric.add(l, acc, labels.shape[0], labels.numel())\n","            timer.stop()\n","            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n","                animator.add(epoch + (i + 1) / num_batches,\n","                             (metric[0] / metric[2], metric[1] / metric[3],\n","                              None))\n","        test_acc = d2l.evaluate_accuracy_gpu(net, test_iter)\n","        animator.add(epoch + 1, (None, None, test_acc))\n","        scheduler.step()\n","    print(f'loss {metric[0] / metric[2]:.3f}, train acc '\n","          f'{metric[1] / metric[3]:.3f}, test acc {test_acc:.3f}')\n","    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec on '\n","          f'{str(devices)}')"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-04-16T11:25:35.454386Z","iopub.status.busy":"2022-04-16T11:25:35.454100Z","iopub.status.idle":"2022-04-16T11:25:35.470808Z","shell.execute_reply":"2022-04-16T11:25:35.469506Z","shell.execute_reply.started":"2022-04-16T11:25:35.454356Z"},"trusted":true},"outputs":[],"source":["def train_fine_tuning(net, learning_rate, batch_size=512, num_epochs=25,\n","                      param_group=True):\n","    train_iter = load_cifar10(True, train_augs, batch_size)\n","    test_iter = load_cifar10(False, test_augs, batch_size)\n","    devices = d2l.try_all_gpus()\n","    loss = nn.CrossEntropyLoss(reduction=\"none\")\n","    if param_group:\n","        params_1x = [param for name, param in net.named_parameters() \n","                     if name not in [\"fc0.weight\", \"fc0.bias\",\n","                                     \"fc1.weight\", \"fc1.bias\",\n","                                     \"fc2.weight\", \"fc2.bias\",\n","                             \"CBAM.CALayer.conv_ca.0.weight\",\"CBAM.CALayer.conv_ca.0.bias\",\n","                             \"CBAM.CALayer.conv_ca.2.weight\",\"CBAM.CALayer.conv_ca.2.bias\",\n","                             \"CBAM.SALayer.conv_sa.0.weight\",\n","                             \"CBAM.SALayer.conv_sa.1.weight\",\n","                             \"CBAM.SALayer.conv_sa.1.bias\"]\n","                    ]\n","        trainer = torch.optim.SGD([{'params': params_1x},\n","                                   {'params': net.fc0.parameters(),'lr': learning_rate * 40},\n","                                   {'params': net.fc1.parameters(),'lr': learning_rate * 30},\n","                                   {'params': net.fc2.parameters(),'lr': learning_rate * 20},\n","                                   {'params': net.CBAM.parameters(),'lr': learning_rate * 10}\n","                                  ],\n","                                lr=learning_rate, weight_decay=0.001)\n","    else:\n","        trainer = torch.optim.SGD(net.parameters(), lr=learning_rate,\n","                                  weight_decay=0.001)\n","    d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs,\n","                   devices)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-04-16T11:25:35.475291Z","iopub.status.busy":"2022-04-16T11:25:35.474801Z","iopub.status.idle":"2022-04-16T12:52:14.517979Z","shell.execute_reply":"2022-04-16T12:52:14.516540Z","shell.execute_reply.started":"2022-04-16T11:25:35.475234Z"},"trusted":true},"outputs":[],"source":["train_fine_tuning(finetune_net, 5e-5)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-04-16T12:52:14.521525Z","iopub.status.busy":"2022-04-16T12:52:14.520985Z","iopub.status.idle":"2022-04-16T12:52:14.526974Z","shell.execute_reply":"2022-04-16T12:52:14.525572Z","shell.execute_reply.started":"2022-04-16T12:52:14.521473Z"},"trusted":true},"outputs":[],"source":["# scratch_net = torchvision.models.resnet18()\n","# scratch_net.fc = nn.Linear(scratch_net.fc.in_features, 10)\n","# train_fine_tuning(scratch_net, 5e-3, param_group=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Runing on Kaggle"]},{"cell_type":"markdown","metadata":{},"source":["- The First"]},{"cell_type":"markdown","metadata":{},"source":["![result1](Cifar10_Result1.png)\n","![result2](Cifar10_Result2.png)"]},{"cell_type":"markdown","metadata":{},"source":["- The second"]},{"cell_type":"markdown","metadata":{},"source":["![result3](Cifar10_Result3.png)"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
